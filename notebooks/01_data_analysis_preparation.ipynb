{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Readiness ML: Data Analysis & Preparation\n",
    "\n",
    "**Project:** Agent-Readiness Assessment System  \n",
    "**Data:** 178 Websites, 41 Binary Features, Expert Scores (0-100)  \n",
    "**Goal:** Analyze data and prepare for ML training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PART 1: DATA LOADING & OVERVIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_excel('../data/raw/178_websites_expert_scores.xlsx')\n",
    "\n",
    "print(f\"âœ“ Data loaded successfully!\")\n",
    "print(f\"  Shape: {df.shape}\")\n",
    "print(f\"  Columns: {df.shape[1]}\")\n",
    "print(f\"  Rows: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show basic info\n",
    "print(\"\\n=\" * 70)\n",
    "print(\"DATA STRUCTURE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify feature types\n",
    "binary_features = [col for col in df.columns if col.startswith('has_')]\n",
    "target_col = 'expert_score' if 'expert_score' in df.columns else [col for col in df.columns if 'score' in col.lower()][0]\n",
    "\n",
    "print(f\"\\nðŸ“Š FEATURE BREAKDOWN:\")\n",
    "print(f\"   Total Features: {len(binary_features)}\")\n",
    "print(f\"   Target Variable: {target_col}\")\n",
    "print(f\"\\nðŸ“‹ BINARY FEATURES (has_*):\\n\")\n",
    "\n",
    "for i, feat in enumerate(binary_features, 1):\n",
    "    print(f\"   {i:2d}. {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 First Look at Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 10 rows\n",
    "print(\"\\nðŸ“„ FIRST 10 ROWS:\\n\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable statistics\n",
    "print(f\"\\nðŸŽ¯ TARGET VARIABLE ({target_col}) STATISTICS:\\n\")\n",
    "print(df[target_col].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PART 2: DATA QUALITY CHECKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing': missing[missing > 0],\n",
    "    'Percentage': missing_pct[missing > 0]\n",
    "})\n",
    "\n",
    "print(\"\\nðŸ” MISSING VALUES CHECK:\\n\")\n",
    "if len(missing_df) == 0:\n",
    "    print(\"   âœ… No missing values found!\")\n",
    "else:\n",
    "    print(missing_df)\n",
    "    print(\"\\n   âš ï¸  Action needed: Handle missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Binary Features Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if binary features are really 0/1\n",
    "print(\"\\nðŸ”¢ BINARY FEATURES VALIDATION:\\n\")\n",
    "\n",
    "invalid_features = []\n",
    "for feat in binary_features:\n",
    "    unique_vals = df[feat].dropna().unique()\n",
    "    if not set(unique_vals).issubset({0, 1}):\n",
    "        invalid_features.append((feat, unique_vals))\n",
    "\n",
    "if len(invalid_features) == 0:\n",
    "    print(\"   âœ… All binary features contain only 0 and 1\")\n",
    "else:\n",
    "    print(\"   âš ï¸  Invalid binary features found:\")\n",
    "    for feat, vals in invalid_features:\n",
    "        print(f\"      {feat}: {vals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Target Variable Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if expert_score is in range 0-100\n",
    "print(f\"\\nðŸŽ¯ TARGET VARIABLE RANGE CHECK ({target_col}):\\n\")\n",
    "\n",
    "min_score = df[target_col].min()\n",
    "max_score = df[target_col].max()\n",
    "\n",
    "print(f\"   Range: [{min_score:.2f}, {max_score:.2f}]\")\n",
    "\n",
    "if min_score >= 0 and max_score <= 100:\n",
    "    print(\"   âœ… Target variable is in valid range [0, 100]\")\n",
    "else:\n",
    "    print(\"   âš ï¸  Target variable outside expected range!\")\n",
    "\n",
    "# Check for outliers using IQR method\n",
    "Q1 = df[target_col].quantile(0.25)\n",
    "Q3 = df[target_col].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = df[(df[target_col] < Q1 - 1.5 * IQR) | (df[target_col] > Q3 + 1.5 * IQR)]\n",
    "\n",
    "print(f\"\\n   Potential outliers (IQR method): {len(outliers)} websites\")\n",
    "if len(outliers) > 0:\n",
    "    print(f\"   Outlier scores: {sorted(outliers[target_col].values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PART 3: EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TARGET VARIABLE: EXPERT SCORE ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "stats = df[target_col].describe()\n",
    "print(f\"\\nðŸ“Š DESCRIPTIVE STATISTICS:\\n\")\n",
    "print(f\"   Count:    {stats['count']:.0f}\")\n",
    "print(f\"   Mean:     {stats['mean']:.2f}\")\n",
    "print(f\"   Std Dev:  {stats['std']:.2f}\")\n",
    "print(f\"   Min:      {stats['min']:.2f}\")\n",
    "print(f\"   25%:      {stats['25%']:.2f}\")\n",
    "print(f\"   Median:   {stats['50%']:.2f}\")\n",
    "print(f\"   75%:      {stats['75%']:.2f}\")\n",
    "print(f\"   Max:      {stats['max']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df[target_col], bins=20, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "axes[0].axvline(df[target_col].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[target_col].mean():.2f}')\n",
    "axes[0].axvline(df[target_col].median(), color='green', linestyle='--', linewidth=2, label=f'Median: {df[target_col].median():.2f}')\n",
    "axes[0].set_xlabel('Expert Score', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Distribution of Expert Scores', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Boxplot\n",
    "box = axes[1].boxplot(df[target_col], vert=True, patch_artist=True, \n",
    "                       boxprops=dict(facecolor='lightblue', color='black'),\n",
    "                       medianprops=dict(color='red', linewidth=2),\n",
    "                       whiskerprops=dict(color='black'),\n",
    "                       capprops=dict(color='black'))\n",
    "axes[1].set_ylabel('Expert Score', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Expert Score Boxplot\\n(Outlier Detection)', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/score_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Saved: outputs/score_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each feature\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FEATURE ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "feature_stats = []\n",
    "\n",
    "for feat in binary_features:\n",
    "    # Count websites with feature\n",
    "    has_feature = df[feat].sum()\n",
    "    pct_has = (has_feature / len(df)) * 100\n",
    "    \n",
    "    # Mean score with vs without feature\n",
    "    mean_with = df[df[feat] == 1][target_col].mean()\n",
    "    mean_without = df[df[feat] == 0][target_col].mean()\n",
    "    score_diff = mean_with - mean_without\n",
    "    \n",
    "    # Correlation\n",
    "    correlation = df[feat].corr(df[target_col])\n",
    "    \n",
    "    feature_stats.append({\n",
    "        'Feature': feat,\n",
    "        'Websites_With (%)': pct_has,\n",
    "        'Mean_Score_With': mean_with,\n",
    "        'Mean_Score_Without': mean_without,\n",
    "        'Score_Difference': score_diff,\n",
    "        'Correlation': correlation\n",
    "    })\n",
    "\n",
    "# Create DataFrame and sort by correlation\n",
    "feature_df = pd.DataFrame(feature_stats)\n",
    "feature_df = feature_df.sort_values('Correlation', ascending=False)\n",
    "\n",
    "print(\"\\nðŸ“Š FEATURE IMPORTANCE (sorted by correlation):\\n\")\n",
    "print(feature_df.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "feature_df.to_csv('../outputs/feature_analysis.csv', index=False)\n",
    "print(\"\\nâœ“ Saved: outputs/feature_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 15 features\n",
    "top_features = feature_df.head(15).copy()\n",
    "top_features['Feature_Short'] = top_features['Feature'].str.replace('has_', '')\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "bars = plt.barh(range(len(top_features)), top_features['Correlation'], color='steelblue', edgecolor='black')\n",
    "\n",
    "# Color bars by correlation strength\n",
    "for i, bar in enumerate(bars):\n",
    "    if top_features.iloc[i]['Correlation'] > 0.5:\n",
    "        bar.set_color('darkgreen')\n",
    "    elif top_features.iloc[i]['Correlation'] > 0.3:\n",
    "        bar.set_color('steelblue')\n",
    "    else:\n",
    "        bar.set_color('lightblue')\n",
    "\n",
    "plt.yticks(range(len(top_features)), top_features['Feature_Short'])\n",
    "plt.xlabel('Correlation with Expert Score', fontsize=12, fontweight='bold')\n",
    "plt.title('Top 15 Most Important Features\\n(Correlation with Expert Score)', fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Saved: outputs/feature_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Feature Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for all features\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FEATURE CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = df[binary_features + [target_col]].corr()\n",
    "\n",
    "# Find highly correlated feature pairs\n",
    "high_corr_pairs = []\n",
    "for i in range(len(binary_features)):\n",
    "    for j in range(i+1, len(binary_features)):\n",
    "        corr_val = corr_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.7:\n",
    "            high_corr_pairs.append((binary_features[i], binary_features[j], corr_val))\n",
    "\n",
    "print(f\"\\nðŸ”— HIGHLY CORRELATED FEATURE PAIRS (|r| > 0.7):\\n\")\n",
    "if len(high_corr_pairs) == 0:\n",
    "    print(\"   No highly correlated pairs found.\")\n",
    "else:\n",
    "    for feat1, feat2, corr in sorted(high_corr_pairs, key=lambda x: abs(x[2]), reverse=True):\n",
    "        print(f\"   {feat1} <-> {feat2}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlation matrix (top 20 features only for readability)\n",
    "top_20_features = feature_df.head(20)['Feature'].tolist()\n",
    "corr_subset = df[top_20_features + [target_col]].corr()\n",
    "\n",
    "plt.figure(figsize=(16, 14))\n",
    "mask = np.triu(np.ones_like(corr_subset, dtype=bool), k=1)\n",
    "sns.heatmap(corr_subset, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Heatmap\\n(Top 20 Features)', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/feature_correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Saved: outputs/feature_correlation_heatmap.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average number of features per website\n",
    "df['feature_count'] = df[binary_features].sum(axis=1)\n",
    "\n",
    "print(f\"\\nðŸ“ˆ FEATURE COUNT PER WEBSITE:\\n\")\n",
    "print(f\"   Mean:   {df['feature_count'].mean():.2f}\")\n",
    "print(f\"   Median: {df['feature_count'].median():.0f}\")\n",
    "print(f\"   Min:    {df['feature_count'].min():.0f}\")\n",
    "print(f\"   Max:    {df['feature_count'].max():.0f}\")\n",
    "print(f\"   Std:    {df['feature_count'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score vs Feature Count\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(df['feature_count'], df[target_col], alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(df['feature_count'], df[target_col], 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(df['feature_count'], p(df['feature_count']), \"r--\", linewidth=2, label=f'Trend: y={z[0]:.2f}x+{z[1]:.2f}')\n",
    "\n",
    "plt.xlabel('Number of Features', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Expert Score', fontsize=12, fontweight='bold')\n",
    "plt.title('Expert Score vs. Number of Features', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/score_vs_feature_count.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Saved: outputs/score_vs_feature_count.png\")\n",
    "\n",
    "# Correlation\n",
    "corr_feature_count = df['feature_count'].corr(df[target_col])\n",
    "print(f\"\\nðŸ“Š Correlation (Feature Count vs Score): {corr_feature_count:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots for top 5 features\n",
    "top_5_features = feature_df.head(5)['Feature'].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(18, 5))\n",
    "\n",
    "for idx, feat in enumerate(top_5_features):\n",
    "    data_with = df[df[feat] == 1][target_col]\n",
    "    data_without = df[df[feat] == 0][target_col]\n",
    "    \n",
    "    axes[idx].boxplot([data_without, data_with], labels=['No', 'Yes'], patch_artist=True,\n",
    "                      boxprops=dict(facecolor='lightblue'),\n",
    "                      medianprops=dict(color='red', linewidth=2))\n",
    "    \n",
    "    feat_short = feat.replace('has_', '')\n",
    "    axes[idx].set_title(f'{feat_short}\\n(r={feature_df[feature_df[\"Feature\"]==feat][\"Correlation\"].values[0]:.3f})', \n",
    "                       fontsize=10, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Expert Score' if idx == 0 else '')\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Expert Score Distribution: Top 5 Most Important Features', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/top5_features_boxplots.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Saved: outputs/top5_features_boxplots.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PART 4: DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DATA SPLITTING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Prepare X and y\n",
    "X = df[binary_features]\n",
    "y = df[target_col]\n",
    "\n",
    "# First split: 80% train+val, 20% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=pd.qcut(y, q=5, duplicates='drop')\n",
    ")\n",
    "\n",
    "# Second split: 70% train (of original), 10% val (of original)\n",
    "# Which means: 7/8 train, 1/8 val of the temp set\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.125, random_state=42, stratify=pd.qcut(y_temp, q=5, duplicates='drop')\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Data split completed!\\n\")\n",
    "print(f\"   Training set:   {len(X_train)} websites ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"   Validation set: {len(X_val)} websites ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"   Test set:       {len(X_test)} websites ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"   Total:          {len(X)} websites\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare score distributions across splits\n",
    "split_stats = pd.DataFrame({\n",
    "    'Split': ['Train', 'Validation', 'Test'],\n",
    "    'Count': [len(y_train), len(y_val), len(y_test)],\n",
    "    'Mean': [y_train.mean(), y_val.mean(), y_test.mean()],\n",
    "    'Std': [y_train.std(), y_val.std(), y_test.std()],\n",
    "    'Min': [y_train.min(), y_val.min(), y_test.min()],\n",
    "    'Max': [y_train.max(), y_val.max(), y_test.max()]\n",
    "})\n",
    "\n",
    "print(f\"\\nðŸ“Š SCORE STATISTICS BY SPLIT:\\n\")\n",
    "print(split_stats.to_string(index=False))\n",
    "\n",
    "# Visualize distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, (split_name, split_data) in enumerate([('Train', y_train), ('Validation', y_val), ('Test', y_test)]):\n",
    "    axes[idx].hist(split_data, bins=15, edgecolor='black', alpha=0.7, color=['steelblue', 'orange', 'green'][idx])\n",
    "    axes[idx].axvline(split_data.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {split_data.mean():.2f}')\n",
    "    axes[idx].set_xlabel('Expert Score', fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Frequency' if idx == 0 else '')\n",
    "    axes[idx].set_title(f'{split_name} Set (n={len(split_data)})', fontsize=12, fontweight='bold')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Score Distribution Across Train/Val/Test Splits', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/split_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Saved: outputs/split_distributions.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"BASELINE MODEL: Mean Prediction\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Baseline: Always predict the mean of training set\n",
    "baseline_prediction = y_train.mean()\n",
    "y_val_pred_baseline = np.full(len(y_val), baseline_prediction)\n",
    "\n",
    "# Calculate metrics\n",
    "baseline_mae = mean_absolute_error(y_val, y_val_pred_baseline)\n",
    "baseline_r2 = r2_score(y_val, y_val_pred_baseline)\n",
    "\n",
    "print(f\"\\nðŸ“Š BASELINE PERFORMANCE (Validation Set):\\n\")\n",
    "print(f\"   Strategy: Always predict mean = {baseline_prediction:.2f}\")\n",
    "print(f\"   MAE:  {baseline_mae:.2f}\")\n",
    "print(f\"   RÂ²:   {baseline_r2:.4f}\")\n",
    "print(f\"\\n   ðŸŽ¯ Goal: Our ML model must beat MAE < {baseline_mae:.2f} and RÂ² > {baseline_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PART 5: SAVE PROCESSED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SAVING PROCESSED DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save feature matrices\n",
    "X_train.to_csv('../data/processed/X_train.csv', index=False)\n",
    "X_val.to_csv('../data/processed/X_val.csv', index=False)\n",
    "X_test.to_csv('../data/processed/X_test.csv', index=False)\n",
    "\n",
    "# Save target variables\n",
    "y_train.to_csv('../data/processed/y_train.csv', index=False, header=['expert_score'])\n",
    "y_val.to_csv('../data/processed/y_val.csv', index=False, header=['expert_score'])\n",
    "y_test.to_csv('../data/processed/y_test.csv', index=False, header=['expert_score'])\n",
    "\n",
    "print(\"\\nâœ“ Successfully saved all datasets:\")\n",
    "print(\"\\n   Features (X):\")\n",
    "print(f\"     - data/processed/X_train.csv ({X_train.shape[0]} rows, {X_train.shape[1]} features)\")\n",
    "print(f\"     - data/processed/X_val.csv ({X_val.shape[0]} rows, {X_val.shape[1]} features)\")\n",
    "print(f\"     - data/processed/X_test.csv ({X_test.shape[0]} rows, {X_test.shape[1]} features)\")\n",
    "print(\"\\n   Targets (y):\")\n",
    "print(f\"     - data/processed/y_train.csv ({len(y_train)} values)\")\n",
    "print(f\"     - data/processed/y_val.csv ({len(y_val)} values)\")\n",
    "print(f\"     - data/processed/y_test.csv ({len(y_test)} values)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PART 6: SUMMARY REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "summary_report = f\"\"\"# Exploratory Data Analysis - Summary Report\n",
    "\n",
    "**Project:** Agent-Readiness ML Assessment  \n",
    "**Date:** {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')}  \n",
    "**Dataset:** 178 Websites, 41 Binary Features\n",
    "\n",
    "---\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "### Data Overview\n",
    "- **Total Websites:** {len(df)}\n",
    "- **Binary Features:** {len(binary_features)}\n",
    "- **Target Variable:** {target_col}\n",
    "- **Score Range:** [{df[target_col].min():.2f}, {df[target_col].max():.2f}]\n",
    "\n",
    "### Data Quality\n",
    "- **Missing Values:** {'None' if df.isnull().sum().sum() == 0 else df.isnull().sum().sum()}\n",
    "- **Binary Features Valid:** {'Yes - All 0/1' if len(invalid_features) == 0 else 'Issues found'}\n",
    "- **Target Range Valid:** {'Yes - [0, 100]' if min_score >= 0 and max_score <= 100 else 'Out of range'}\n",
    "\n",
    "### Target Variable Statistics\n",
    "- **Mean Score:** {df[target_col].mean():.2f} Â± {df[target_col].std():.2f}\n",
    "- **Median Score:** {df[target_col].median():.2f}\n",
    "- **Range:** [{df[target_col].min():.2f}, {df[target_col].max():.2f}]\n",
    "- **Outliers (IQR):** {len(outliers)} websites\n",
    "\n",
    "### Feature Insights\n",
    "- **Average Features per Website:** {df['feature_count'].mean():.2f}\n",
    "- **Feature Count Range:** [{df['feature_count'].min():.0f}, {df['feature_count'].max():.0f}]\n",
    "- **Correlation (Feature Count vs Score):** {corr_feature_count:.3f}\n",
    "\n",
    "---\n",
    "\n",
    "## Top 10 Most Important Features\n",
    "\n",
    "**Ranked by Correlation with Expert Score:**\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Add top 10 features\n",
    "top_10 = feature_df.head(10)\n",
    "for idx, row in top_10.iterrows():\n",
    "    feat_name = row['Feature'].replace('has_', '')\n",
    "    summary_report += f\"{top_10.index.get_loc(idx) + 1}. **{feat_name}**\\n\"\n",
    "    summary_report += f\"   - Correlation: {row['Correlation']:.3f}\\n\"\n",
    "    summary_report += f\"   - Websites with feature: {row['Websites_With (%)']:.1f}%\\n\"\n",
    "    summary_report += f\"   - Score WITH: {row['Mean_Score_With']:.2f} | WITHOUT: {row['Mean_Score_Without']:.2f} (Î”={row['Score_Difference']:.2f})\\n\\n\"\n",
    "\n",
    "summary_report += f\"\"\"---\n",
    "\n",
    "## Data Splits\n",
    "\n",
    "| Split      | Count | Mean Score | Std Dev | Min   | Max   |\n",
    "|------------|-------|------------|---------|-------|-------|\n",
    "| Train      | {len(y_train)}   | {y_train.mean():.2f}      | {y_train.std():.2f}    | {y_train.min():.2f} | {y_train.max():.2f} |\n",
    "| Validation | {len(y_val)}    | {y_val.mean():.2f}      | {y_val.std():.2f}    | {y_val.min():.2f} | {y_val.max():.2f} |\n",
    "| Test       | {len(y_test)}    | {y_test.mean():.2f}      | {y_test.std():.2f}    | {y_test.min():.2f} | {y_test.max():.2f} |\n",
    "\n",
    "---\n",
    "\n",
    "## Baseline Model Performance\n",
    "\n",
    "**Strategy:** Always predict training mean ({baseline_prediction:.2f})\n",
    "\n",
    "- **MAE (Validation):** {baseline_mae:.2f}\n",
    "- **RÂ² (Validation):** {baseline_r2:.4f}\n",
    "\n",
    "**Goal:** ML model must achieve:\n",
    "- MAE < {baseline_mae:.2f}\n",
    "- RÂ² > {baseline_r2:.4f}\n",
    "\n",
    "---\n",
    "\n",
    "## Problems Found\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "problems = []\n",
    "if df.isnull().sum().sum() > 0:\n",
    "    problems.append(\"- Missing values detected - requires imputation\")\n",
    "if len(invalid_features) > 0:\n",
    "    problems.append(\"- Non-binary values in has_* features\")\n",
    "if len(outliers) > 0:\n",
    "    problems.append(f\"- {len(outliers)} potential outliers detected (consider robustness)\")\n",
    "if len(high_corr_pairs) > 0:\n",
    "    problems.append(f\"- {len(high_corr_pairs)} highly correlated feature pairs (consider multicollinearity)\")\n",
    "\n",
    "if len(problems) == 0:\n",
    "    summary_report += \"âœ… **No critical issues found!**\\n\"\n",
    "else:\n",
    "    for problem in problems:\n",
    "        summary_report += f\"{problem}\\n\"\n",
    "\n",
    "summary_report += f\"\"\"\\n---\n",
    "\n",
    "## Expectations for Training\n",
    "\n",
    "### Promising Indicators:\n",
    "1. **Strong feature correlations** - Top features show correlations > 0.4\n",
    "2. **Clear score differences** - Features create meaningful separation\n",
    "3. **Linear relationship** - Feature count correlates with score ({corr_feature_count:.3f})\n",
    "4. **Clean data** - {'No missing values' if df.isnull().sum().sum() == 0 else 'Minimal data issues'}\n",
    "\n",
    "### Recommended Approaches:\n",
    "1. **Linear Models** (Ridge, Lasso) - Good baseline for binary features\n",
    "2. **Tree-based Models** (Random Forest, XGBoost) - Handle feature interactions\n",
    "3. **Feature Engineering** - Consider feature combinations for top correlated pairs\n",
    "4. **Cross-validation** - Use k-fold to ensure robust performance\n",
    "\n",
    "### Expected Performance:\n",
    "- **Target MAE:** < {baseline_mae * 0.7:.2f} (30% improvement over baseline)\n",
    "- **Target RÂ²:** > 0.5 (moderate to strong predictive power)\n",
    "\n",
    "---\n",
    "\n",
    "## Generated Outputs\n",
    "\n",
    "**Visualizations:**\n",
    "- `score_distribution.png` - Score histogram and boxplot\n",
    "- `feature_importance.png` - Top 15 features by correlation\n",
    "- `feature_correlation_heatmap.png` - Feature correlation matrix\n",
    "- `score_vs_feature_count.png` - Scatter plot with trend line\n",
    "- `top5_features_boxplots.png` - Score distribution for top 5 features\n",
    "- `split_distributions.png` - Train/val/test score distributions\n",
    "\n",
    "**Data Files:**\n",
    "- `data/processed/X_train.csv`, `X_val.csv`, `X_test.csv`\n",
    "- `data/processed/y_train.csv`, `y_val.csv`, `y_test.csv`\n",
    "- `outputs/feature_analysis.csv`\n",
    "\n",
    "---\n",
    "\n",
    "**Ready for Model Training! ðŸš€**\n",
    "\"\"\"\n",
    "\n",
    "# Save report\n",
    "with open('../outputs/eda_summary.md', 'w') as f:\n",
    "    f.write(summary_report)\n",
    "\n",
    "print(\"\\nâœ“ Saved: outputs/eda_summary.md\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ… DATA ANALYSIS & PREPARATION COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Steps\n",
    "\n",
    "1. **Model Training** - Implement Linear Regression, Random Forest, XGBoost\n",
    "2. **Hyperparameter Tuning** - Optimize model parameters\n",
    "3. **Model Evaluation** - Compare performance metrics\n",
    "4. **Feature Engineering** - Create interaction features if needed\n",
    "5. **Final Testing** - Evaluate best model on test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
